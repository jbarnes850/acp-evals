# ACP Evals Configuration
# Copy this file to .env and fill in your API keys

# ========================================
# LLM Provider Configuration
# ========================================
# Choose one or more providers for evaluation
# The framework will auto-detect available providers

# OpenAI
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4.1 
OPENAI_API_BASE=https://api.openai.com/v1  # Optional: for custom endpoints

# Anthropic
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-4-sonnet

# Ollama (Local LLMs)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=Qwen3:8B  

# ========================================
# Evaluation Settings
# ========================================
# Default provider for evaluations
EVALUATION_PROVIDER=openai  # Options: openai, anthropic, ollama, mock

# LLM parameters for consistent evaluation
EVALUATION_TEMPERATURE=0.0  # 0.0 for deterministic, up to 2.0 for creative
EVALUATION_MAX_TOKENS=1000  # Maximum tokens for evaluation responses
EVALUATION_TIMEOUT=30  # Timeout in seconds for LLM calls

# ========================================
# ACP Server Configuration
# ========================================
# Required only if evaluating ACP agents via URL
ACP_SERVER_URL=http://localhost:8000
ACP_AGENT_NAME=default

# ========================================
# Advanced Settings
# ========================================
# Retry configuration
MAX_RETRIES=3
RETRY_DELAY=1  # Seconds between retries

# Logging
LOG_LEVEL=INFO  # Options: DEBUG, INFO, WARNING, ERROR
LOG_LLM_CALLS=false  # Log all LLM calls for debugging

# Cache settings
ENABLE_CACHE=true  # Cache LLM responses for identical inputs
CACHE_TTL=3600  # Cache time-to-live in seconds

# Cost tracking
TRACK_COSTS=true  # Track and report LLM API costs
COST_WARNING_THRESHOLD=10.0  # Warn if costs exceed this amount in USD